<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CS231 Assignment 2 Q2-BatchNormalization, Notplus">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>CS231 Assignment 2 Q2-BatchNormalization | Notplus</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.0.0"><link rel="alternate" href="/atom.xml" title="Notplus" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Notplus</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Notplus</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/notplus" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/notplus" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CS231 Assignment 2 Q2-BatchNormalization</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Deep-Learning/">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                            <a href="/tags/Assignment/">
                                <span class="chip bg-color">Assignment</span>
                            </a>
                        
                            <a href="/tags/CS231n/">
                                <span class="chip bg-color">CS231n</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                CS231 Assignment
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-01-14
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2020-08-02
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    1.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    11 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。<br>所有代码均已上传到GitHub项目<a target="_blank" rel="noopener" href="https://github.com/notplus/cs231n-assignment/tree/master/assignment2">cs231n-assignment2</a></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="1-batch-normalization-forward"><a href="#1-batch-normalization-forward" class="headerlink" title="1. batch normalization forward"></a>1. batch normalization forward</h3><p><strong>实现思路:</strong> 参考论文[1]，通过如下公式计算<br><img src="https://raw.githubusercontent.com/wuliutx/upload-pic/master/20200203194911.png" alt="20200203194911.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">batchnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> bn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Forward pass for batch normalization.

    During training the sample mean and (uncorrected) sample variance are
    computed from minibatch statistics and used to normalize the incoming data.
    During training we also keep an exponentially decaying running mean of the
    mean and variance of each feature, and these averages are used to normalize
    data at test-time.

    At each timestep we update the running averages for mean and variance using
    an exponential decay based on the momentum parameter:

    running_mean = momentum * running_mean + (1 - momentum) * sample_mean
    running_var = momentum * running_var + (1 - momentum) * sample_var

    Note that the batch normalization paper suggests a different test-time
    behavior: they compute sample mean and variance for each feature using a
    large number of training images rather than using a running average. For
    this implementation we have chosen to use running averages instead since
    they do not require an additional estimation step; the torch7
    implementation of batch normalization also uses running averages.

    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - bn_param: Dictionary with the following keys:
      - mode: 'train' or 'test'; required
      - eps: Constant for numeric stability
      - momentum: Constant for running mean / variance.
      - running_mean: Array of shape (D,) giving running mean of features
      - running_var Array of shape (D,) giving running variance of features

    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    """</span>
    mode <span class="token operator">=</span> bn_param<span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span>
    eps <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'eps'</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    momentum <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'momentum'</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">)</span>

    N<span class="token punctuation">,</span> D <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    running_mean <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'running_mean'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
    running_var <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'running_var'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>

    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> None<span class="token punctuation">,</span> None
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true"># TODO: Implement the training-time forward pass for batch norm.      #</span>
        <span class="token comment" spellcheck="true"># Use minibatch statistics to compute the mean and variance, use      #</span>
        <span class="token comment" spellcheck="true"># these statistics to normalize the incoming data, and scale and      #</span>
        <span class="token comment" spellcheck="true"># shift the normalized data using gamma and beta.                     #</span>
        <span class="token comment" spellcheck="true">#                                                                     #</span>
        <span class="token comment" spellcheck="true"># You should store the output in the variable out. Any intermediates  #</span>
        <span class="token comment" spellcheck="true"># that you need for the backward pass should be stored in the cache   #</span>
        <span class="token comment" spellcheck="true"># variable.                                                           #</span>
        <span class="token comment" spellcheck="true">#                                                                     #</span>
        <span class="token comment" spellcheck="true"># You should also use your computed sample mean and variance together #</span>
        <span class="token comment" spellcheck="true"># with the momentum variable to update the running mean and running   #</span>
        <span class="token comment" spellcheck="true"># variance, storing your result in the running_mean and running_var   #</span>
        <span class="token comment" spellcheck="true"># variables.                                                          #</span>
        <span class="token comment" spellcheck="true">#                                                                     #</span>
        <span class="token comment" spellcheck="true"># Note that though you should be keeping track of the running         #</span>
        <span class="token comment" spellcheck="true"># variance, you should normalize the data based on the standard       #</span>
        <span class="token comment" spellcheck="true"># deviation (square root of variance) instead!                        # </span>
        <span class="token comment" spellcheck="true"># Referencing the original paper (https://arxiv.org/abs/1502.03167)   #</span>
        <span class="token comment" spellcheck="true"># might prove to be helpful.                                          #</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        sample_mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        sample_var <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sample_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        out <span class="token operator">=</span> gamma <span class="token operator">*</span> x_hat <span class="token operator">+</span> beta
        cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> sample_mean<span class="token punctuation">,</span> sample_var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat<span class="token punctuation">)</span>
        running_mean <span class="token operator">=</span> momentum <span class="token operator">*</span> running_mean <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> sample_mean
        running_var <span class="token operator">=</span> momentum <span class="token operator">*</span> running_var <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> sample_var        

        <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true">#                           END OF YOUR CODE                          #</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
    <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">'test'</span><span class="token punctuation">:</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true"># TODO: Implement the test-time forward pass for batch normalization. #</span>
        <span class="token comment" spellcheck="true"># Use the running mean and variance to normalize the incoming data,   #</span>
        <span class="token comment" spellcheck="true"># then scale and shift the normalized data using gamma and beta.      #</span>
        <span class="token comment" spellcheck="true"># Store the result in the out variable.                               #</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> running_mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>running_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
        out <span class="token operator">=</span> gamma <span class="token operator">*</span> x_hat <span class="token operator">+</span> beta

        <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
        <span class="token comment" spellcheck="true">#                          END OF YOUR CODE                           #</span>
        <span class="token comment" spellcheck="true">#######################################################################</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Invalid forward batchnorm mode "%s"'</span> <span class="token operator">%</span> mode<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># Store the updated running means back into bn_param</span>
    bn_param<span class="token punctuation">[</span><span class="token string">'running_mean'</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_mean
    bn_param<span class="token punctuation">[</span><span class="token string">'running_var'</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_var

    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache
</code></pre>
<h3 id="2-batch-normalization-backward"><a href="#2-batch-normalization-backward" class="headerlink" title="2. batch normalization backward"></a>2. batch normalization backward</h3><p><strong>实现思路：</strong> 通过计算图反向传播计算梯度，较为繁琐，可参考下一个实现    </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">batchnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Backward pass for batch normalization.

    For this implementation, you should write out a computation graph for
    batch normalization on paper and propagate gradients backward through
    intermediate nodes.

    Inputs:
    - dout: Upstream derivatives, of shape (N, D)
    - cache: Variable of intermediates from batchnorm_forward.

    Returns a tuple of:
    - dx: Gradient with respect to inputs x, of shape (N, D)
    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)
    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for batch normalization. Store the    #</span>
    <span class="token comment" spellcheck="true"># results in the dx, dgamma, and dbeta variables.                         #</span>
    <span class="token comment" spellcheck="true"># Referencing the original paper (https://arxiv.org/abs/1502.03167)       #</span>
    <span class="token comment" spellcheck="true"># might prove to be helpful.                                              #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat <span class="token operator">=</span> cache
    m <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    dx_hat <span class="token operator">=</span> dout <span class="token operator">*</span> gamma
    dvar <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dmean <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx_hat <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">+</span> dmean <span class="token operator">/</span> m

    dx_1 <span class="token operator">=</span> dout <span class="token operator">*</span> gamma
    dx_2_b <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> dx_1<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dx_2_a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> dx_1
    dx_3_b <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> dx_2_b
    dx_4_b <span class="token operator">=</span> dx_3_b <span class="token operator">*</span> <span class="token number">1</span>
    dx_5_b <span class="token operator">=</span> np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">*</span> dx_4_b
    dx_6_b <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> dx_5_b
    dx_7_a <span class="token operator">=</span> dx_6_b <span class="token operator">*</span> <span class="token number">1</span> <span class="token operator">+</span> dx_2_a <span class="token operator">*</span> <span class="token number">1</span>
    dx_7_b <span class="token operator">=</span> dx_6_b <span class="token operator">*</span> <span class="token number">1</span> <span class="token operator">+</span> dx_2_a <span class="token operator">*</span> <span class="token number">1</span>
    dx_8_b <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_7_b<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dx_9_b <span class="token operator">=</span> np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">*</span> dx_8_b
    dx_10 <span class="token operator">=</span> dx_9_b <span class="token operator">+</span> dx_7_a

    dx <span class="token operator">=</span> dx_10
    dgamma <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout <span class="token operator">*</span> x_hat<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dbeta <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>

    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta</code></pre>
<h3 id="3-batch-normalization-backward-更为简洁的实现"><a href="#3-batch-normalization-backward-更为简洁的实现" class="headerlink" title="3. batch normalization backward 更为简洁的实现"></a>3. batch normalization backward 更为简洁的实现</h3><p><strong>实现思路:</strong><br>通过论文[1]所给公式计算，可以自己推导一遍<br><img src="https://raw.githubusercontent.com/wuliutx/upload-pic/master/20200203195253.png" alt="20200203195253.png">    </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">batchnorm_backward_alt</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Alternative backward pass for batch normalization.

    For this implementation you should work out the derivatives for the batch
    normalizaton backward pass on paper and simplify as much as possible. You
    should be able to derive a simple expression for the backward pass. 
    See the jupyter notebook for more hints.

    Note: This implementation should expect to receive the same cache variable
    as batchnorm_backward, but might not use all of the values in the cache.

    Inputs / outputs: Same as batchnorm_backward
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for batch normalization. Store the    #</span>
    <span class="token comment" spellcheck="true"># results in the dx, dgamma, and dbeta variables.                         #</span>
    <span class="token comment" spellcheck="true">#                                                                         #</span>
    <span class="token comment" spellcheck="true"># After computing the gradient with respect to the centered inputs, you   #</span>
    <span class="token comment" spellcheck="true"># should be able to compute gradients with respect to the inputs in a     #</span>
    <span class="token comment" spellcheck="true"># single statement; our implementation fits on a single 80-character line.#</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat <span class="token operator">=</span> cache
    m <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    dx_hat <span class="token operator">=</span> dout <span class="token operator">*</span> gamma
    dvar <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dmean <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx_hat <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">+</span> dmean <span class="token operator">/</span> m
    dgamma <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout <span class="token operator">*</span> x_hat<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dbeta <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>

    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta</code></pre>
<h3 id="4-layer-normalization-forward-amp-backward"><a href="#4-layer-normalization-forward-amp-backward" class="headerlink" title="4. layer normalization forward &amp; backward"></a>4. layer normalization forward &amp; backward</h3><p><strong>实现思路:</strong> 根据论文[2]，layer normalization与batch normalization在实现上极为相似，只需加入转置</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">layernorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> ln_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Forward pass for layer normalization.

    During both training and test-time, the incoming data is normalized per data-point,
    before being scaled by gamma and beta parameters identical to that of batch normalization.

    Note that in contrast to batch normalization, the behavior during train and test-time for
    layer normalization are identical, and we do not need to keep track of running averages
    of any sort.

    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - ln_param: Dictionary with the following keys:
        - eps: Constant for numeric stability

    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> None<span class="token punctuation">,</span> None
    eps <span class="token operator">=</span> ln_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'eps'</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the training-time forward pass for layer norm.          #</span>
    <span class="token comment" spellcheck="true"># Normalize the incoming data, and scale and  shift the normalized data   #</span>
    <span class="token comment" spellcheck="true">#  using gamma and beta.                                                  #</span>
    <span class="token comment" spellcheck="true"># HINT: this can be done by slightly modifying your training-time         #</span>
    <span class="token comment" spellcheck="true"># implementation of  batch normalization, and inserting a line or two of  #</span>
    <span class="token comment" spellcheck="true"># well-placed code. In particular, can you think of any matrix            #</span>
    <span class="token comment" spellcheck="true"># transformations you could perform, that would enable you to copy over   #</span>
    <span class="token comment" spellcheck="true"># the batch norm code and leave it almost unchanged?                      #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x <span class="token operator">=</span> x<span class="token punctuation">.</span>T
    sample_mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    sample_var <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sample_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    out <span class="token operator">=</span> gamma <span class="token operator">*</span> x_hat<span class="token punctuation">.</span>T <span class="token operator">+</span> beta
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> sample_mean<span class="token punctuation">,</span> sample_var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">layernorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Backward pass for layer normalization.

    For this implementation, you can heavily rely on the work you've done already
    for batch normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, D)
    - cache: Variable of intermediates from layernorm_forward.

    Returns a tuple of:
    - dx: Gradient with respect to inputs x, of shape (N, D)
    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)
    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for layer norm.                       #</span>
    <span class="token comment" spellcheck="true">#                                                                         #</span>
    <span class="token comment" spellcheck="true"># HINT: this can be done by slightly modifying your training-time         #</span>
    <span class="token comment" spellcheck="true"># implementation of batch normalization. The hints to the forward pass    #</span>
    <span class="token comment" spellcheck="true"># still apply!                                                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat <span class="token operator">=</span> cache
    m <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    dx_hat <span class="token operator">=</span> <span class="token punctuation">(</span>dout <span class="token operator">*</span> gamma<span class="token punctuation">)</span><span class="token punctuation">.</span>T
    dvar <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dmean <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx_hat <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">+</span> dmean <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>T
    dgamma <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout <span class="token operator">*</span> x_hat<span class="token punctuation">.</span>T<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    dbeta <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta</code></pre>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本次作业主要是batch normalization 和 layer normalization 层的前向、反向传播实现，通过BN、LN层可大大加快神经网络训练<br>速度，并且加入BN层对于权重的初始化较不敏感。作业难点在与梯度计算，但论文已给出相关公式。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">Sergey Ioffe and Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, ICML 2015.</a></li>
<li>[2] <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.06450.pdf">Ba, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. “Layer Normalization.” stat 1050 (2016): 21.</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/21560667">CS231n课程笔记翻译：神经网络笔记 2</a></li>
<li><a target="_blank" rel="noopener" href="http://blog.a-stack.com/2019/01/12/Batch-Normalization-%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96/">Batch-Normalization(批量归一化)</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/duan_zhihua/article/details/83107615">cs 231 Batch Normalization 求导推导及代码复现(BN,LN</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/lightaime/cs231n">lightaime/cs231n</a></li>
</ul>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">notplus</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://notplus.cn/2020/01/14/assignment-2-q2-batchnormalization/">http://notplus.cn/2020/01/14/assignment-2-q2-batchnormalization/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">notplus</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Deep-Learning/">
                                    <span class="chip bg-color">Deep Learning</span>
                                </a>
                            
                                <a href="/tags/Assignment/">
                                    <span class="chip bg-color">Assignment</span>
                                </a>
                            
                                <a href="/tags/CS231n/">
                                    <span class="chip bg-color">CS231n</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/01/15/assignment-2-q3-dropout/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="CS231 Assignment 2 Q3-Dropout">
                        
                        <span class="card-title">CS231 Assignment 2 Q3-Dropout</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Introduction本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。所有代码均已上传到GitHub项目cs231n-assignment2
Code1. dropout forward实现思路: 参考论文[1],整体实现
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-01-15
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                    CS231 Assignment
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                    <a href="/tags/Assignment/">
                        <span class="chip bg-color">Assignment</span>
                    </a>
                    
                    <a href="/tags/CS231n/">
                        <span class="chip bg-color">CS231n</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/01/13/assignment-2-q1-fullyconnectednet/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="CS231 Assignment 2 Q1-FullyConnectedNet">
                        
                        <span class="card-title">CS231 Assignment 2 Q1-FullyConnectedNet</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Introduction本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。所有代码均已上传到GitHub项目cs231n-assignment2
Code1. affine layer forward &amp; backwa
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-01-13
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                    CS231 Assignment
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                    <a href="/tags/Assignment/">
                        <span class="chip bg-color">Assignment</span>
                    </a>
                    
                    <a href="/tags/CS231n/">
                        <span class="chip bg-color">CS231n</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="/about" target="_blank">notplus</a>
            <!-- |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a> -->
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">17.9k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/notplus" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:notplus@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=513140802" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 513140802" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/notplus" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/notplus" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
