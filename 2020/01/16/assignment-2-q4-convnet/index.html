<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CS231 Assignment 2 Q4-ConvNet, Notplus">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>CS231 Assignment 2 Q4-ConvNet | Notplus</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Notplus" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Notplus</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Notplus</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/notplus" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/notplus" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/16.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CS231 Assignment 2 Q4-ConvNet</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Deep-Learning/">
                                <span class="chip bg-color">Deep Learning</span>
                            </a>
                        
                            <a href="/tags/Assignment/">
                                <span class="chip bg-color">Assignment</span>
                            </a>
                        
                            <a href="/tags/CS231n/">
                                <span class="chip bg-color">CS231n</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                CS231 Assignment
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-01-16
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2020-08-02
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    3.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    19 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。<br>所有代码均已上传到GitHub项目<a href="https://github.com/notplus/cs231n-assignment/tree/master/assignment2" target="_blank" rel="noopener">cs231n-assignment2</a></p>
<h2 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h2><h3 id="1-Convolution-Naive-forward"><a href="#1-Convolution-Naive-forward" class="headerlink" title="1. Convolution: Naive forward"></a>1. Convolution: Naive forward</h3><p><strong>实现思路:</strong> 通过循环计算卷积层前向传播，效率较低</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">conv_forward_naive</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> conv_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A naive implementation of the forward pass for a convolutional layer.

    The input consists of N data points, each with C channels, height H and
    width W. We convolve each input with F different filters, where each filter
    spans all C channels and has height HH and width WW.

    Input:
    - x: Input data of shape (N, C, H, W)
    - w: Filter weights of shape (F, C, HH, WW)
    - b: Biases, of shape (F,)
    - conv_param: A dictionary with the following keys:
      - 'stride': The number of pixels between adjacent receptive fields in the
        horizontal and vertical directions.
      - 'pad': The number of pixels that will be used to zero-pad the input.


    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)
    along the height and width axes of the input. Be careful not to modfiy the original
    input x directly.

    Returns a tuple of:
    - out: Output data, of shape (N, F, H', W') where H' and W' are given by
      H' = 1 + (H + 2 * pad - HH) / stride
      W' = 1 + (W + 2 * pad - WW) / stride
    - cache: (x, w, b, conv_param)
    """</span>
    out <span class="token operator">=</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the convolutional forward pass.                         #</span>
    <span class="token comment" spellcheck="true"># Hint: you can use the function np.pad for padding.                      #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    pad <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span>
    stride <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
    x_new <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>pad<span class="token punctuation">,</span>pad<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>pad<span class="token punctuation">,</span>pad<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'constant'</span><span class="token punctuation">)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    F<span class="token punctuation">,</span> _<span class="token punctuation">,</span> HH<span class="token punctuation">,</span> WW <span class="token operator">=</span> w<span class="token punctuation">.</span>shape
    H_new <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> pad <span class="token operator">-</span> HH<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    W_new <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> pad <span class="token operator">-</span> WW<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    out <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span>F<span class="token punctuation">,</span>H_new<span class="token punctuation">,</span>W_new<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>H_new<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>W_new<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_masked <span class="token operator">=</span> x_new<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>HH<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>WW<span class="token punctuation">]</span>        
        <span class="token keyword">for</span> c <span class="token keyword">in</span> range<span class="token punctuation">(</span>F<span class="token punctuation">)</span><span class="token punctuation">:</span>
          out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>c<span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>x_masked <span class="token operator">*</span> w<span class="token punctuation">[</span>c<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">[</span>c<span class="token punctuation">]</span>


    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> conv_param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache
</code></pre>
<h3 id="2-convolutional-backward"><a href="#2-convolutional-backward" class="headerlink" title="2. convolutional backward"></a>2. convolutional backward</h3><p><strong>实现思路：</strong> 求导计算梯度，进行反向传播      </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">conv_backward_naive</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A naive implementation of the backward pass for a convolutional layer.

    Inputs:
    - dout: Upstream derivatives.
    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive

    Returns a tuple of:
    - dx: Gradient with respect to x
    - dw: Gradient with respect to w
    - db: Gradient with respect to b
    """</span>
    dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the convolutional backward pass.                        #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> conv_param <span class="token operator">=</span> cache
    pad <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'pad'</span><span class="token punctuation">]</span>
    stride <span class="token operator">=</span> conv_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
    x_pad <span class="token operator">=</span> np<span class="token punctuation">.</span>pad<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>pad<span class="token punctuation">,</span>pad<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>pad<span class="token punctuation">,</span>pad<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'constant'</span><span class="token punctuation">)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    F<span class="token punctuation">,</span> _<span class="token punctuation">,</span> HH<span class="token punctuation">,</span> WW <span class="token operator">=</span> w<span class="token punctuation">.</span>shape
    H_new <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> pad <span class="token operator">-</span> HH<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    W_new <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">*</span> pad <span class="token operator">-</span> WW<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    dx <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    dw <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
    db <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    dx_pad <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x_pad<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>H_new<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>W_new<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_masked <span class="token operator">=</span> x_pad<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>HH<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>WW<span class="token punctuation">]</span>        
        <span class="token keyword">for</span> c <span class="token keyword">in</span> range<span class="token punctuation">(</span>F<span class="token punctuation">)</span><span class="token punctuation">:</span>
          dw<span class="token punctuation">[</span>c <span class="token punctuation">,</span><span class="token punctuation">:</span> <span class="token punctuation">,</span><span class="token punctuation">:</span> <span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>x_masked <span class="token operator">*</span> <span class="token punctuation">(</span>dout<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> c<span class="token punctuation">,</span> i<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> n <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">:</span>
          dx_pad<span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>HH<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>WW<span class="token punctuation">]</span> <span class="token operator">+=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>w<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>dout<span class="token punctuation">[</span>n<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    dx <span class="token operator">=</span> dx_pad<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>pad<span class="token punctuation">:</span><span class="token operator">-</span>pad<span class="token punctuation">,</span>pad<span class="token punctuation">:</span><span class="token operator">-</span>pad<span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db
</code></pre>
<h3 id="3-Max-Pooling-Naive-forward"><a href="#3-Max-Pooling-Naive-forward" class="headerlink" title="3. Max-Pooling: Naive forward"></a>3. Max-Pooling: Naive forward</h3><p><strong>实现思路：</strong> 简单方式计算Maxpooling前向传播      </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">max_pool_forward_naive</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> pool_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A naive implementation of the forward pass for a max-pooling layer.

    Inputs:
    - x: Input data, of shape (N, C, H, W)
    - pool_param: dictionary with the following keys:
      - 'pool_height': The height of each pooling region
      - 'pool_width': The width of each pooling region
      - 'stride': The distance between adjacent pooling regions

    No padding is necessary here. Output size is given by

    Returns a tuple of:
    - out: Output data, of shape (N, C, H', W') where H' and W' are given by
      H' = 1 + (H - pool_height) / stride
      W' = 1 + (W - pool_width) / stride
    - cache: (x, pool_param)
    """</span>
    out <span class="token operator">=</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the max-pooling forward pass                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    pool_height <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_height'</span><span class="token punctuation">]</span>
    pool_width <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_width'</span><span class="token punctuation">]</span>
    stride <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
    H_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> pool_height<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    W_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> pool_width<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    out <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span>C<span class="token punctuation">,</span>H_out<span class="token punctuation">,</span>W_out<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>H_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>W_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_masked <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>pool_height<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>pool_width<span class="token punctuation">]</span>
        out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x_masked<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> pool_param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache
</code></pre>
<h3 id="4-Max-Pooling-Naive-backward"><a href="#4-Max-Pooling-Naive-backward" class="headerlink" title="4. Max-Pooling: Naive backward"></a>4. Max-Pooling: Naive backward</h3><p><strong>实现思路：</strong> 简单方式计算Maxpooling反向传播      </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">max_pool_backward_naive</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A naive implementation of the backward pass for a max-pooling layer.

    Inputs:
    - dout: Upstream derivatives
    - cache: A tuple of (x, pool_param) as in the forward pass.

    Returns:
    - dx: Gradient with respect to x
    """</span>
    dx <span class="token operator">=</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the max-pooling backward pass                           #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> pool_param <span class="token operator">=</span> cache
    dx <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    pool_height <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_height'</span><span class="token punctuation">]</span>
    pool_width <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_width'</span><span class="token punctuation">]</span>
    stride <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
    H_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> pool_height<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    W_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> pool_width<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>H_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>W_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_masked <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>pool_height<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>pool_width<span class="token punctuation">]</span>
        max_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x_masked<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        temp_mask <span class="token operator">=</span> x_masked <span class="token operator">==</span> <span class="token punctuation">(</span>max_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">]</span>
        dx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>pool_height<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>pool_width<span class="token punctuation">]</span> <span class="token operator">+=</span> temp_mask <span class="token operator">*</span> <span class="token punctuation">(</span>dout<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">]</span>


    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> dx
</code></pre>
<h3 id="5-Max-Pooling-Naive-backward"><a href="#5-Max-Pooling-Naive-backward" class="headerlink" title="5. Max-Pooling: Naive backward"></a>5. Max-Pooling: Naive backward</h3><p><strong>实现思路：</strong> 简单方式计算Maxpooling反向传播      </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">max_pool_backward_naive</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A naive implementation of the backward pass for a max-pooling layer.

    Inputs:
    - dout: Upstream derivatives
    - cache: A tuple of (x, pool_param) as in the forward pass.

    Returns:
    - dx: Gradient with respect to x
    """</span>
    dx <span class="token operator">=</span> None
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the max-pooling backward pass                           #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> pool_param <span class="token operator">=</span> cache
    dx <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    pool_height <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_height'</span><span class="token punctuation">]</span>
    pool_width <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'pool_width'</span><span class="token punctuation">]</span>
    stride <span class="token operator">=</span> pool_param<span class="token punctuation">[</span><span class="token string">'stride'</span><span class="token punctuation">]</span>
    H_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H <span class="token operator">-</span> pool_height<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>
    W_out <span class="token operator">=</span> int<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> <span class="token punctuation">(</span>W <span class="token operator">-</span> pool_width<span class="token punctuation">)</span> <span class="token operator">/</span> stride<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>H_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>W_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x_masked <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>pool_height<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>pool_width<span class="token punctuation">]</span>
        max_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>x_masked<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        temp_mask <span class="token operator">=</span> x_masked <span class="token operator">==</span> <span class="token punctuation">(</span>max_mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">]</span>
        dx<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token operator">*</span>stride<span class="token punctuation">:</span>i<span class="token operator">*</span>stride<span class="token operator">+</span>pool_height<span class="token punctuation">,</span>j<span class="token operator">*</span>stride<span class="token punctuation">:</span>j<span class="token operator">*</span>stride<span class="token operator">+</span>pool_width<span class="token punctuation">]</span> <span class="token operator">+=</span> temp_mask <span class="token operator">*</span> <span class="token punctuation">(</span>dout<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span>None<span class="token punctuation">,</span>None<span class="token punctuation">]</span>


    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> dx
</code></pre>
<h3 id="6-简单三层卷积神经网络"><a href="#6-简单三层卷积神经网络" class="headerlink" title="6 简单三层卷积神经网络"></a>6 简单三层卷积神经网络</h3><p><strong>实现思路：</strong></p>
<ul>
<li>初始化和之前相同，权重采用高斯分布，偏差使用零初始化</li>
<li>前向传播和反向传播与之前三层全连接层实现类似，都是通过已经写好的前向/反向传播组合计算</li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ThreeLayerConvNet</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A three-layer convolutional network with the following architecture:

    conv - relu - 2x2 max pool - affine - relu - affine - softmax

    The network operates on minibatches of data that have shape (N, C, H, W)
    consisting of N images, each with height H and width W and with C input
    channels.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_filters<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> filter_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>
                 hidden_dim<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> weight_scale<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> reg<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
                 dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Initialize a new network.

        Inputs:
        - input_dim: Tuple (C, H, W) giving size of input data
        - num_filters: Number of filters to use in the convolutional layer
        - filter_size: Width/height of filters to use in the convolutional layer
        - hidden_dim: Number of units to use in the fully-connected hidden layer
        - num_classes: Number of scores to produce from the final affine layer.
        - weight_scale: Scalar giving standard deviation for random initialization
          of weights.
        - reg: Scalar giving L2 regularization strength
        - dtype: numpy datatype to use for computation.
        """</span>
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>reg <span class="token operator">=</span> reg
        self<span class="token punctuation">.</span>dtype <span class="token operator">=</span> dtype

        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># TODO: Initialize weights and biases for the three-layer convolutional    #</span>
        <span class="token comment" spellcheck="true"># network. Weights should be initialized from a Gaussian centered at 0.0   #</span>
        <span class="token comment" spellcheck="true"># with standard deviation equal to weight_scale; biases should be          #</span>
        <span class="token comment" spellcheck="true"># initialized to zero. All weights and biases should be stored in the      #</span>
        <span class="token comment" spellcheck="true">#  dictionary self.params. Store weights and biases for the convolutional  #</span>
        <span class="token comment" spellcheck="true"># layer using the keys 'W1' and 'b1'; use keys 'W2' and 'b2' for the       #</span>
        <span class="token comment" spellcheck="true"># weights and biases of the hidden affine layer, and keys 'W3' and 'b3'    #</span>
        <span class="token comment" spellcheck="true"># for the weights and biases of the output affine layer.                   #</span>
        <span class="token comment" spellcheck="true">#                                                                          #</span>
        <span class="token comment" spellcheck="true"># IMPORTANT: For this assignment, you can assume that the padding          #</span>
        <span class="token comment" spellcheck="true"># and stride of the first convolutional layer are chosen so that           #</span>
        <span class="token comment" spellcheck="true"># **the width and height of the input are preserved**. Take a look at      #</span>
        <span class="token comment" spellcheck="true"># the start of the loss() function to see how that happens.                #                           </span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> input_dim
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span>num_filters<span class="token punctuation">,</span>C<span class="token punctuation">,</span>filter_size<span class="token punctuation">,</span>filter_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_filters<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>int<span class="token punctuation">(</span>H<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">*</span>int<span class="token punctuation">(</span>W<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token operator">*</span>num_filters<span class="token punctuation">,</span>hidden_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span>

        <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                             #</span>
        <span class="token comment" spellcheck="true">############################################################################</span>

        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> v<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>dtype<span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Evaluate loss and gradient for the three-layer convolutional network.

        Input / output: Same API as TwoLayerNet in fc_net.py.
        """</span>
        W1<span class="token punctuation">,</span> b1 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span>
        W2<span class="token punctuation">,</span> b2 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span>
        W3<span class="token punctuation">,</span> b3 <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># pass conv_param to the forward pass for the convolutional layer</span>
        <span class="token comment" spellcheck="true"># Padding and stride chosen to preserve the input spatial size</span>
        filter_size <span class="token operator">=</span> W1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
        conv_param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'stride'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'pad'</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>filter_size <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">}</span>

        <span class="token comment" spellcheck="true"># pass pool_param to the forward pass for the max-pooling layer</span>
        pool_param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'pool_height'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'pool_width'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'stride'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">}</span>

        scores <span class="token operator">=</span> None
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># TODO: Implement the forward pass for the three-layer convolutional net,  #</span>
        <span class="token comment" spellcheck="true"># computing the class scores for X and storing them in the scores          #</span>
        <span class="token comment" spellcheck="true"># variable.                                                                #</span>
        <span class="token comment" spellcheck="true">#                                                                          #</span>
        <span class="token comment" spellcheck="true"># Remember you can use the functions defined in cs231n/fast_layers.py and  #</span>
        <span class="token comment" spellcheck="true"># cs231n/layer_utils.py in your implementation (already imported).         #</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        a1<span class="token punctuation">,</span> a1_cache <span class="token operator">=</span> conv_relu_pool_forward<span class="token punctuation">(</span>X<span class="token punctuation">,</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>conv_param<span class="token punctuation">,</span>pool_param<span class="token punctuation">)</span>
        a2<span class="token punctuation">,</span> a2_cache <span class="token operator">=</span> affine_relu_forward<span class="token punctuation">(</span>a1<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        a3<span class="token punctuation">,</span> a3_cache <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>a2<span class="token punctuation">,</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        scores <span class="token operator">=</span> a3

        <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                             #</span>
        <span class="token comment" spellcheck="true">############################################################################</span>

        <span class="token keyword">if</span> y <span class="token keyword">is</span> None<span class="token punctuation">:</span>
            <span class="token keyword">return</span> scores

        loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for the three-layer convolutional net, #</span>
        <span class="token comment" spellcheck="true"># storing the loss and gradients in the loss and grads variables. Compute  #</span>
        <span class="token comment" spellcheck="true"># data loss using softmax, and make sure that grads[k] holds the gradients #</span>
        <span class="token comment" spellcheck="true"># for self.params[k]. Don't forget to add L2 regularization!               #</span>
        <span class="token comment" spellcheck="true">#                                                                          #</span>
        <span class="token comment" spellcheck="true"># NOTE: To ensure that your implementation matches ours and you pass the   #</span>
        <span class="token comment" spellcheck="true"># automated tests, make sure that your L2 regularization includes a factor #</span>
        <span class="token comment" spellcheck="true"># of 0.5 to simplify the expression for the gradient.                      #</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

        loss<span class="token punctuation">,</span> dscores <span class="token operator">=</span> softmax_loss<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        loss <span class="token operator">+=</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        dx<span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b3'</span><span class="token punctuation">]</span> <span class="token operator">=</span> affine_backward<span class="token punctuation">(</span>dscores<span class="token punctuation">,</span>a3_cache<span class="token punctuation">)</span>
        dx<span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> affine_relu_backward<span class="token punctuation">(</span>dx<span class="token punctuation">,</span> a2_cache<span class="token punctuation">)</span>
        dx<span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grads<span class="token punctuation">[</span><span class="token string">'b1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> conv_relu_pool_backward<span class="token punctuation">(</span>dx<span class="token punctuation">,</span> a1_cache<span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W3'</span><span class="token punctuation">]</span>
        grads<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W2'</span><span class="token punctuation">]</span>
        grads<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W1'</span><span class="token punctuation">]</span>

        <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
        <span class="token comment" spellcheck="true">############################################################################</span>
        <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                             #</span>
        <span class="token comment" spellcheck="true">############################################################################</span>

        <span class="token keyword">return</span> loss<span class="token punctuation">,</span> grads</code></pre>
<h3 id="7-spatial-batch-normalization-forward-amp-amp-backward"><a href="#7-spatial-batch-normalization-forward-amp-amp-backward" class="headerlink" title="7. spatial batch normalization forward &amp;&amp; backward"></a>7. spatial batch normalization forward &amp;&amp; backward</h3><p><strong>实现思路：</strong></p>
<ul>
<li>参考论文 [1] ，batch normalization 在卷积层的实现，不同于全连接的实现，由于要保留原有的空间结构且减少计算量，故将每一个channel作为feature进行归一化    </li>
<li>由于与之前实现的全连接bn层十分类似，可以直接调用之前的函数，只需对输入输出进行reshape   </li>
</ul>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">spatial_batchnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> bn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the forward pass for spatial batch normalization.

    Inputs:
    - x: Input data of shape (N, C, H, W)
    - gamma: Scale parameter, of shape (C,)
    - beta: Shift parameter, of shape (C,)
    - bn_param: Dictionary with the following keys:
      - mode: 'train' or 'test'; required
      - eps: Constant for numeric stability
      - momentum: Constant for running mean / variance. momentum=0 means that
        old information is discarded completely at every time step, while
        momentum=1 means that new information is never incorporated. The
        default of momentum=0.9 should work well in most situations.
      - running_mean: Array of shape (D,) giving running mean of features
      - running_var Array of shape (D,) giving running variance of features

    Returns a tuple of:
    - out: Output data, of shape (N, C, H, W)
    - cache: Values needed for the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> None<span class="token punctuation">,</span> None

    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the forward pass for spatial batch normalization.       #</span>
    <span class="token comment" spellcheck="true">#                                                                         #</span>
    <span class="token comment" spellcheck="true"># HINT: You can implement spatial batch normalization by calling the      #</span>
    <span class="token comment" spellcheck="true"># vanilla version of batch normalization you implemented above.           #</span>
    <span class="token comment" spellcheck="true"># Your implementation should be very short; ours is less than five lines. #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    <span class="token comment" spellcheck="true"># (N,D) (D,)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    temp_out<span class="token punctuation">,</span> cache <span class="token operator">=</span> batchnorm_forward<span class="token punctuation">(</span>x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>N<span class="token operator">*</span>H<span class="token operator">*</span>W<span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>gamma<span class="token punctuation">,</span>beta<span class="token punctuation">,</span>bn_param<span class="token punctuation">)</span>
    out <span class="token operator">=</span> temp_out<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> W<span class="token punctuation">,</span> H<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>

    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache

<span class="token keyword">def</span> <span class="token function">spatial_batchnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the backward pass for spatial batch normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, C, H, W)
    - cache: Values from the forward pass

    Returns a tuple of:
    - dx: Gradient with respect to inputs, of shape (N, C, H, W)
    - dgamma: Gradient with respect to scale parameter, of shape (C,)
    - dbeta: Gradient with respect to shift parameter, of shape (C,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None

    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for spatial batch normalization.      #</span>
    <span class="token comment" spellcheck="true">#                                                                         #</span>
    <span class="token comment" spellcheck="true"># HINT: You can implement spatial batch normalization by calling the      #</span>
    <span class="token comment" spellcheck="true"># vanilla version of batch normalization you implemented above.           #</span>
    <span class="token comment" spellcheck="true"># Your implementation should be very short; ours is less than five lines. #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> dout<span class="token punctuation">.</span>shape
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> batchnorm_backward_alt<span class="token punctuation">(</span>dout<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token operator">*</span>H<span class="token operator">*</span>W<span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">,</span> cache<span class="token punctuation">)</span>
    dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span>W<span class="token punctuation">,</span>H<span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>

    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta
</code></pre>
<h3 id="8-spatial-groupnorm-forward-amp-amp-backward"><a href="#8-spatial-groupnorm-forward-amp-amp-backward" class="headerlink" title="8. spatial groupnorm forward &amp;&amp; backward"></a>8. spatial groupnorm forward &amp;&amp; backward</h3><p><strong>实现思路：</strong></p>
<ul>
<li>参考论文[2] 分组进行归一化   </li>
</ul>
<p><img src="https://raw.githubusercontent.com/wuliutx/upload-pic/master/20200207211202.png" alt="20200207211202.png"></p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">spatial_groupnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> G<span class="token punctuation">,</span> gn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the forward pass for spatial group normalization.
    In contrast to layer normalization, group normalization splits each entry 
    in the data into G contiguous pieces, which it then normalizes independently.
    Per feature shifting and scaling are then applied to the data, in a manner identical to that of batch normalization and layer normalization.

    Inputs:
    - x: Input data of shape (N, C, H, W)
    - gamma: Scale parameter, of shape (C,)
    - beta: Shift parameter, of shape (C,)
    - G: Integer mumber of groups to split into, should be a divisor of C
    - gn_param: Dictionary with the following keys:
      - eps: Constant for numeric stability

    Returns a tuple of:
    - out: Output data, of shape (N, C, H, W)
    - cache: Values needed for the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> None<span class="token punctuation">,</span> None
    eps <span class="token operator">=</span> gn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'eps'</span><span class="token punctuation">,</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the forward pass for spatial group normalization.       #</span>
    <span class="token comment" spellcheck="true"># This will be extremely similar to the layer norm implementation.        #</span>
    <span class="token comment" spellcheck="true"># In particular, think about how you could transform the matrix so that   #</span>
    <span class="token comment" spellcheck="true"># the bulk of the code is similar to both train-time batch normalization  #</span>
    <span class="token comment" spellcheck="true"># and layer normalization!                                                # </span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    x_trans <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> G<span class="token punctuation">,</span> C <span class="token operator">//</span> G<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>
    sample_mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x_trans<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    sample_var <span class="token operator">=</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>x_trans<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    x_hat <span class="token operator">=</span> <span class="token punctuation">(</span>x_trans <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sample_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>
    x_hat <span class="token operator">=</span> x_hat<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>
    out <span class="token operator">=</span> gamma <span class="token operator">*</span> x_hat <span class="token operator">+</span> beta
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> sample_mean<span class="token punctuation">,</span> sample_var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat<span class="token punctuation">,</span> G<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">spatial_groupnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes the backward pass for spatial group normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, C, H, W)
    - cache: Values from the forward pass

    Returns a tuple of:
    - dx: Gradient with respect to inputs, of shape (N, C, H, W)
    - dgamma: Gradient with respect to scale parameter, of shape (C,)
    - dbeta: Gradient with respect to shift parameter, of shape (C,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> None<span class="token punctuation">,</span> None<span class="token punctuation">,</span> None

    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># TODO: Implement the backward pass for spatial group normalization.      #</span>
    <span class="token comment" spellcheck="true"># This will be extremely similar to the layer norm implementation.        #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true"># *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>

    x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> mean<span class="token punctuation">,</span> var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> x_hat<span class="token punctuation">,</span> G <span class="token operator">=</span> cache
    dgamma <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout <span class="token operator">*</span> x_hat<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    dbeta <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    x_trans <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> G<span class="token punctuation">,</span> C <span class="token operator">//</span> G<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>
    m <span class="token operator">=</span> C <span class="token operator">//</span> G <span class="token operator">*</span> H <span class="token operator">*</span> W
    dx_hat <span class="token operator">=</span> <span class="token punctuation">(</span>dout <span class="token operator">*</span> gamma<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> G<span class="token punctuation">,</span> C <span class="token operator">//</span> G<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>
    dvar <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span>x_trans <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>power<span class="token punctuation">(</span><span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    dmean <span class="token operator">=</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>dx_hat <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x_trans <span class="token operator">-</span> mean<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx_hat <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> <span class="token operator">+</span> dvar <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>x_trans <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> m <span class="token operator">+</span> dmean <span class="token operator">/</span> m
    dx <span class="token operator">=</span> dx<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token comment" spellcheck="true">#                             END OF YOUR CODE                            #</span>
    <span class="token comment" spellcheck="true">###########################################################################</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta</code></pre>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本次作业主要是有关卷积神经网络的一系列实现，包括卷积层、池化层、BN层的前反向传播实现，对于Group BN 还是没弄清楚。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">Sergey Ioffe and Christian Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, ICML 2015.</a></li>
<li>[2] <a href="https://arxiv.org/abs/1803.08494" target="_blank" rel="noopener">Wu, Yuxin, and Kaiming He. “Group Normalization.” arXiv preprint arXiv:1803.08494 (2018).</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/21560667" target="_blank" rel="noopener">CS231n课程笔记翻译：神经网络笔记 2</a></li>
<li><a href="https://blog.csdn.net/mooneve/article/details/83858012" target="_blank" rel="noopener">Group Normalization</a></li>
<li><a href="https://github.com/lightaime/cs231n" target="_blank" rel="noopener">lightaime/cs231n</a></li>
</ul>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">notplus</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://notplus.cn/2020/01/16/assignment-2-q4-convnet/">http://notplus.cn/2020/01/16/assignment-2-q4-convnet/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">notplus</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Deep-Learning/">
                                    <span class="chip bg-color">Deep Learning</span>
                                </a>
                            
                                <a href="/tags/Assignment/">
                                    <span class="chip bg-color">Assignment</span>
                                </a>
                            
                                <a href="/tags/CS231n/">
                                    <span class="chip bg-color">CS231n</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2020/01/17/assignment-2-q5-pytorch.15/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/3.jpg" class="responsive-img" alt="CS231 Assignment 2 Q5-PyTorch">
                        
                        <span class="card-title">CS231 Assignment 2 Q5-PyTorch</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Introduction本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。所有代码均已上传到GitHub项目cs231n-assignment2
Code1. 实现一个三层全连接神经网络实现思路: 通过PyTorch实现一个三
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2020-01-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                    CS231 Assignment
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                    <a href="/tags/Assignment/">
                        <span class="chip bg-color">Assignment</span>
                    </a>
                    
                    <a href="/tags/CS231n/">
                        <span class="chip bg-color">CS231n</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/01/15/assignment-2-q3-dropout/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="CS231 Assignment 2 Q3-Dropout">
                        
                        <span class="card-title">CS231 Assignment 2 Q3-Dropout</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Introduction本文为斯坦福大学CS231n课程作业及总结，若有错误，欢迎指正。所有代码均已上传到GitHub项目cs231n-assignment2
Code1. dropout forward实现思路: 参考论文[1],整体实现
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-01-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/CS231-Assignment/" class="post-category">
                                    CS231 Assignment
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Deep-Learning/">
                        <span class="chip bg-color">Deep Learning</span>
                    </a>
                    
                    <a href="/tags/Assignment/">
                        <span class="chip bg-color">Assignment</span>
                    </a>
                    
                    <a href="/tags/CS231n/">
                        <span class="chip bg-color">CS231n</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2020</span>
            <a href="/about" target="_blank">notplus</a>
            <!-- |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a> -->
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">17.8k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "6";
                    var startDate = "28";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/notplus" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:notplus@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=513140802" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 513140802" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>





    <a href="https://www.zhihu.com/people/notplus" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/notplus" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
